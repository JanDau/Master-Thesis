{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code\n",
    "...\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import json \n",
    "from sdmetrics.single_column import MissingValueSimilarity, BoundaryAdherence, CategoryAdherence, RangeCoverage, CategoryCoverage\n",
    "from sdmetrics.reports.single_table import DiagnosticReport, QualityReport\n",
    "from typing import Optional, Tuple, Union\n",
    "from scipy.stats import skew, kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "SAVE_DATA = True  # Whether to save generated figures and CSVs\n",
    "\n",
    "# File paths\n",
    "REAL_FILE = \"20250301_data_20250510_122405_final_100_train.csv\"\n",
    "SYNTH_FILE = \"20250301_data_20250510_122405_final_100_synth.csv\"\n",
    "HOLDOUT_FILE = \"20250301_data_20250510_122405_final_100_holdout.csv\"\n",
    "METADATA_FILE = \"20250301_data_20250510_122405_final_metadata.json\"\n",
    "\n",
    "# Define directories for input and output\n",
    "notebook_dir = Path().resolve() # Get the current working directory\n",
    "DATA_DIR = Path(\"../../data\")\n",
    "OUTPUT_DIR_CSV = notebook_dir / \"results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dtypes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Konvertiert bestimmte Spalten des DataFrames in die gewünschten Datentypen:\n",
    "     - definierte Spalten als category\n",
    "     - definierte Spalten als pandas Nullable Integer (Int64)\n",
    "     - consciousness_level und news_score als geordnete Categoricals\n",
    "    \"\"\"\n",
    "    df = df.copy()  # Änderungen nicht am Original vornehmen\n",
    "\n",
    "    # 1) Kategorische Spalten\n",
    "    cat_cols = ['gender', 'ethnicity', 'chief_complaint', 'icd_block']\n",
    "    for col in cat_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "    # 2) Integer-Spalten mit Nullable Integer dtype\n",
    "    int_cols = ['age', 'systolic_bp', 'diastolic_bp',\n",
    "                'heart_rate', 'respiratory_rate', 'oxygen_saturation']\n",
    "    for col in int_cols:\n",
    "        df[col] = df[col].astype('Int64')\n",
    "\n",
    "    # 3) Geordnete Categoricals\n",
    "    df['consciousness_level'] = pd.Categorical(\n",
    "        df['consciousness_level'],\n",
    "        categories=['A', 'C', 'V', 'P', 'U'],\n",
    "        ordered=True\n",
    "    )\n",
    "    df['news_score'] = pd.Categorical(\n",
    "        df['news_score'],\n",
    "        categories=list(range(19)),\n",
    "        ordered=True\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_data(\n",
    "    real_filename: Union[str, Path],\n",
    "    synth_filename: Optional[Union[str, Path]] = None,\n",
    "    holdout_filename: Optional[Union[str, Path]] = None,\n",
    "    data_dir: Path = DATA_DIR\n",
    ") -> Tuple[pd.DataFrame, Optional[pd.DataFrame], Optional[pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Lädt die realen, synthetischen und optionalen Holdout-CSV-Dateien\n",
    "    aus data_dir und wandelt sie über convert_dtypes um.\n",
    "\n",
    "    Returns:\n",
    "        df_real: pd.DataFrame\n",
    "        df_synth: Optional[pd.DataFrame]\n",
    "        df_holdout: Optional[pd.DataFrame]\n",
    "    \"\"\"\n",
    "    def _read_and_convert(fn: Union[str, Path]) -> pd.DataFrame:\n",
    "        return (\n",
    "            pd.read_csv(data_dir / fn, low_memory=False)\n",
    "              .pipe(convert_dtypes)\n",
    "        )\n",
    "\n",
    "    df_real    = _read_and_convert(real_filename)\n",
    "    df_synth   = _read_and_convert(synth_filename)   if synth_filename   else None\n",
    "    df_holdout = _read_and_convert(holdout_filename) if holdout_filename else None\n",
    "\n",
    "    return df_real, df_synth, df_holdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kategorien_uebersicht(df_real, df_synth, kategorien):\n",
    "    zusammenfassung = []\n",
    "\n",
    "    for spalte in kategorien:\n",
    "        real_serie = df_real[spalte].astype('category')\n",
    "        synth_serie = df_synth[spalte].astype('category')\n",
    "\n",
    "        real_info = real_serie.describe()\n",
    "        synth_info = synth_serie.describe()\n",
    "\n",
    "        zusammenfassung.append({\n",
    "            'Spalte': spalte,\n",
    "            'Real_Unique': real_info['unique'],\n",
    "            'Synth_Unique': synth_info['unique'],\n",
    "            'Real_Top': real_info['top'],\n",
    "            'Synth_Top': synth_info['top'],\n",
    "            'Real_Freq': real_serie.value_counts(normalize=True).iloc[0],\n",
    "            'Synth_Freq': synth_serie.value_counts(normalize=True).iloc[0],\n",
    "            # 'Real_Freq': real_info['freq'],\n",
    "            # 'Synth_Freq': synth_info['freq'],\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(zusammenfassung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerische_uebersicht(df_real, df_synth, numerisch):\n",
    "    zusammenfassung = []\n",
    "\n",
    "    for spalte in numerisch:\n",
    "        real_serie = df_real[spalte].dropna()\n",
    "        synth_serie = df_synth[spalte].dropna()\n",
    "\n",
    "        zusammenfassung.append({\n",
    "            'Spalte': spalte,\n",
    "            'Real_Median': real_serie.median(),\n",
    "            'Synth_Median': synth_serie.median(),\n",
    "            'Real_Q1': real_serie.quantile(0.25),\n",
    "            'Synth_Q1': synth_serie.quantile(0.25),\n",
    "            'Real_Q3': real_serie.quantile(0.75),\n",
    "            'Synth_Q3': synth_serie.quantile(0.75),\n",
    "            'Real_IQR': real_serie.quantile(0.75) - real_serie.quantile(0.25),\n",
    "            'Synth_IQR': synth_serie.quantile(0.75) - synth_serie.quantile(0.25),\n",
    "            'Real_Min': real_serie.min(),\n",
    "            'Synth_Min': synth_serie.min(),\n",
    "            'Real_Max': real_serie.max(),\n",
    "            'Synth_Max': synth_serie.max(),\n",
    "            'Real_Skew': skew(real_serie),\n",
    "            'Synth_Skew': skew(synth_serie),\n",
    "            'Real_Kurtosis': kurtosis(real_serie),  # excess kurtosis\n",
    "            'Synth_Kurtosis': kurtosis(synth_serie),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(zusammenfassung)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR_CSV.mkdir(parents=True, exist_ok=True)  # Ensure output dir exists\n",
    "\n",
    "with open(DATA_DIR / METADATA_FILE, 'r') as f:\n",
    "    my_metadata_dict = json.load(f)\n",
    "\n",
    "df_real, df_synth, df_holdout = load_data(REAL_FILE, SYNTH_FILE, HOLDOUT_FILE)\n",
    "\n",
    "ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Missing Values (Redundant, as Filtered Out Prior CTGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 16)\n",
      "(0, 16)\n"
     ]
    }
   ],
   "source": [
    "df_missing_real = df_real[df_real.isna().any(axis=1)].reset_index(drop=True)\n",
    "print(df_missing_real.shape)\n",
    "\n",
    "df_missing_synth = df_synth[df_synth.isna().any(axis=1)].reset_index(drop=True)\n",
    "print(df_missing_synth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "results = [\n",
    "    MissingValueSimilarity.compute(\n",
    "        real_data=df_real[col],\n",
    "        synthetic_data=df_synth[col]\n",
    "    )\n",
    "    for col in df_real.columns\n",
    "]\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category and Boundary Adherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating report ...\n",
      "\n",
      "(1/2) Evaluating Data Validity: |██████████| 16/16 [00:00<00:00, 347.72it/s]|\n",
      "Data Validity Score: 99.93%\n",
      "\n",
      "(2/2) Evaluating Data Structure: |██████████| 1/1 [00:00<00:00, 1001.74it/s]|\n",
      "Data Structure Score: 100.0%\n",
      "\n",
      "Overall Score (Average): 99.96%\n",
      "\n",
      "--------------------------\n",
      "Get Properties:          Property     Score\n",
      "0   Data Validity  0.999267\n",
      "1  Data Structure  1.000000\n",
      "--------------------------\n",
      "Get Score: 0.9996335467584156\n",
      "--------------------------\n",
      "Get Details, Data Structure:            Metric  Score\n",
      "0  TableStructure    1.0\n"
     ]
    }
   ],
   "source": [
    "report = DiagnosticReport()\n",
    "report.generate(df_real, df_synth, my_metadata_dict)\n",
    "print(\"--------------------------\")\n",
    "print(f\"Get Properties: {report.get_properties()}\")\n",
    "print(\"--------------------------\")\n",
    "print(f\"Get Score: {report.get_score()}\")\n",
    "print(\"--------------------------\")\n",
    "print(f\"Get Details, Data Structure: {report.get_details(property_name='Data Structure')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Column             Metric     Score\n",
      "0     icu_admission_24h  CategoryAdherence  1.000000\n",
      "1                   age  BoundaryAdherence  0.988273\n",
      "2                gender  CategoryAdherence  1.000000\n",
      "3             ethnicity  CategoryAdherence  1.000000\n",
      "4   consciousness_level  CategoryAdherence  1.000000\n",
      "5           temperature  BoundaryAdherence  1.000000\n",
      "6            heart_rate  BoundaryAdherence  1.000000\n",
      "7      respiratory_rate  BoundaryAdherence  1.000000\n",
      "8     oxygen_saturation  BoundaryAdherence  1.000000\n",
      "9           systolic_bp  BoundaryAdherence  1.000000\n",
      "10         diastolic_bp  BoundaryAdherence  1.000000\n",
      "11           news_score  CategoryAdherence  1.000000\n",
      "12        night_arrival  CategoryAdherence  1.000000\n",
      "13      weekend_arrival  CategoryAdherence  1.000000\n",
      "14      chief_complaint  CategoryAdherence  1.000000\n",
      "15            icd_block  CategoryAdherence  1.000000\n"
     ]
    }
   ],
   "source": [
    "export = report.get_details(property_name='Data Validity')\n",
    "print(export)\n",
    "# if SAVE_DATA:\n",
    "    # export.to_csv(OUTPUT_DIR_CSV / f'adherence_{ts}.csv', index=False, sep=';', decimal=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category and Range Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Column            Metric     Score\n",
      "0     icu_admission_24h  CategoryCoverage  1.000000\n",
      "1                   age     RangeCoverage  1.000000\n",
      "2                gender  CategoryCoverage  1.000000\n",
      "3             ethnicity  CategoryCoverage  1.000000\n",
      "4   consciousness_level  CategoryCoverage  1.000000\n",
      "5           temperature     RangeCoverage  0.397163\n",
      "6            heart_rate     RangeCoverage  0.637681\n",
      "7      respiratory_rate     RangeCoverage  0.372881\n",
      "8     oxygen_saturation     RangeCoverage  0.260000\n",
      "9           systolic_bp     RangeCoverage  0.736607\n",
      "10         diastolic_bp     RangeCoverage  0.872000\n",
      "11           news_score  CategoryCoverage  1.000000\n",
      "12        night_arrival  CategoryCoverage  1.000000\n",
      "13      weekend_arrival  CategoryCoverage  1.000000\n",
      "14      chief_complaint  CategoryCoverage  1.000000\n",
      "15            icd_block  CategoryCoverage  1.000000\n"
     ]
    }
   ],
   "source": [
    "num_attrs = df_real.select_dtypes(include=['number']).columns\n",
    "cat_attrs = df_real.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# compute all scores up front\n",
    "num_scores = {\n",
    "    attr: RangeCoverage.compute(\n",
    "        real_data=df_real[attr], synthetic_data=df_synth[attr]\n",
    "    )\n",
    "    for attr in num_attrs\n",
    "}\n",
    "cat_scores = {\n",
    "    attr: CategoryCoverage.compute(\n",
    "        real_data=df_real[attr], synthetic_data=df_synth[attr]\n",
    "    )\n",
    "    for attr in cat_attrs\n",
    "}\n",
    "\n",
    "# build the result rows in the same column order as df_real\n",
    "rows = []\n",
    "for col in df_real.columns:\n",
    "    if col in num_scores:\n",
    "        rows.append({\n",
    "            'Column': col,\n",
    "            'Metric': 'RangeCoverage',\n",
    "            'Score': num_scores[col]\n",
    "        })\n",
    "    elif col in cat_scores:\n",
    "        rows.append({\n",
    "            'Column': col,\n",
    "            'Metric': 'CategoryCoverage',\n",
    "            'Score': cat_scores[col]\n",
    "        })\n",
    "    else:\n",
    "        # skip any extra columns\n",
    "        continue\n",
    "\n",
    "# assemble into a DataFrame and print\n",
    "result_df = pd.DataFrame(rows)\n",
    "print(result_df)\n",
    "# if SAVE_DATA:\n",
    "    # result_df.to_csv(OUTPUT_DIR_CSV / f'coverage_{ts}.csv', index=False, sep=';', decimal=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Spalte  Real_Unique  Synth_Unique Real_Top Synth_Top  \\\n",
      "0    icu_admission_24h            2             2    False     False   \n",
      "1               gender            2             2        F         F   \n",
      "2            ethnicity            5             5    White     White   \n",
      "3  consciousness_level            5             4        A         A   \n",
      "4           news_score           14            10        0         0   \n",
      "5        night_arrival            2             2    False     False   \n",
      "6      weekend_arrival            2             2    False     False   \n",
      "7      chief_complaint          309           309    Other     Other   \n",
      "8            icd_block          219           219  I30-I5A   A30-A49   \n",
      "\n",
      "   Real_Freq  Synth_Freq  Coverage  Adherence  \n",
      "0   0.876739    0.906392       1.0        1.0  \n",
      "1   0.514653    0.589623       1.0        1.0  \n",
      "2   0.680677    0.624589       1.0        1.0  \n",
      "3   0.919055    0.967345       1.0        1.0  \n",
      "4   0.362962    0.369171       1.0        1.0  \n",
      "5   0.812875    0.821710       1.0        1.0  \n",
      "6   0.713189    0.564419       1.0        1.0  \n",
      "7   0.275746    0.240953       1.0        1.0  \n",
      "8   0.047608    0.083663       1.0        1.0  \n"
     ]
    }
   ],
   "source": [
    "stats_cats = kategorien_uebersicht(df_real, df_synth, cat_attrs)\n",
    "stats_cats = stats_cats.merge(result_df[['Column', 'Score']].rename(columns={'Column': 'Spalte'}), on='Spalte', how='left')\n",
    "stats_cats = stats_cats.rename(columns={'Score': 'Coverage'})\n",
    "stats_cats = stats_cats.merge(export[['Column', 'Score']].rename(columns={'Column': 'Spalte'}), on='Spalte', how='left')\n",
    "stats_cats = stats_cats.rename(columns={'Score': 'Adherence'})\n",
    "print(stats_cats)\n",
    "if SAVE_DATA:\n",
    "    stats_cats.to_csv(OUTPUT_DIR_CSV / f'cat_stats_{ts}.csv', index=False, sep=';', decimal=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Spalte  Real_Median  Synth_Median  Real_Q1  Synth_Q1  Real_Q3  \\\n",
      "0                age         61.0          61.0     47.0      52.0     74.0   \n",
      "1        temperature         36.7          36.7     36.4      36.4     37.0   \n",
      "2         heart_rate         85.0          81.0     73.0      75.0     99.0   \n",
      "3   respiratory_rate         18.0          18.0     16.0      16.0     18.0   \n",
      "4  oxygen_saturation         98.0          99.0     97.0      98.0    100.0   \n",
      "5        systolic_bp        132.0         137.0    117.0     117.0    149.0   \n",
      "6       diastolic_bp         75.0          75.0     64.0      64.0     85.0   \n",
      "\n",
      "   Synth_Q3  Real_IQR  Synth_IQR  Real_Min  Synth_Min  Real_Max  Synth_Max  \\\n",
      "0      75.0      27.0       23.0      18.0       18.0      91.0       95.0   \n",
      "1      36.9       0.6        0.5      30.0       35.0      44.1       40.6   \n",
      "2      98.0      26.0       23.0      20.0       40.0     227.0      172.0   \n",
      "3      18.0       2.0        2.0       1.0       13.0      60.0       35.0   \n",
      "4     100.0       3.0        2.0      50.0       87.0     100.0      100.0   \n",
      "5     151.0      32.0       34.0      50.0       65.0     274.0      230.0   \n",
      "6      88.0      21.0       24.0      25.0       29.0     150.0      138.0   \n",
      "\n",
      "   Real_Skew  Synth_Skew  Real_Kurtosis  Synth_Kurtosis  Coverage  Adherence  \n",
      "0  -0.315096   -0.295227      -0.676088       -0.530906  1.000000   0.988273  \n",
      "1   1.029419    1.917178       6.581872        5.542992  0.397163   1.000000  \n",
      "2   0.509172    1.135889       0.456056        1.305660  0.637681   1.000000  \n",
      "3   2.643767    1.545197      15.217085        2.511797  0.372881   1.000000  \n",
      "4  -2.446473   -1.759394      17.018628        3.342313  0.260000   1.000000  \n",
      "5   0.537317    0.085119       0.625631       -0.404664  0.736607   1.000000  \n",
      "6   0.255247   -0.089753       0.390739       -0.771021  0.872000   1.000000  \n"
     ]
    }
   ],
   "source": [
    "stats_num = numerische_uebersicht(df_real, df_synth, num_attrs)\n",
    "stats_num = stats_num.merge(result_df[['Column', 'Score']].rename(columns={'Column': 'Spalte'}), on='Spalte', how='left')\n",
    "stats_num = stats_num.rename(columns={'Score': 'Coverage'})\n",
    "stats_num = stats_num.merge(export[['Column', 'Score']].rename(columns={'Column': 'Spalte'}), on='Spalte', how='left')\n",
    "stats_num = stats_num.rename(columns={'Score': 'Adherence'})\n",
    "print(stats_num)\n",
    "if SAVE_DATA:\n",
    "    stats_num.to_csv(OUTPUT_DIR_CSV / f'num_stats_{ts}.csv', index=False, sep=';', decimal=',', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDMetrics",
   "language": "python",
   "name": "sdmetrics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
