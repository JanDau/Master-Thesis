{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code\n",
    "\n",
    "**Vital Parameters**\n",
    "- Temperature: >= 50 assumed Fahrenheit; 30 <= x <= 45 °C (excludes 58 rows)\n",
    "- Heart Rate: 20 <= x <= 240 (exludes 12 rows)\n",
    "- Respiratory Rate: 1 <= x <= 70 (excludes 15 rows)\n",
    "- O2 Saturation: 20 <= x <= 100 (excludes 51 rows)\n",
    "- Systolic BP: 30 <= x <= 300 (excludes 63 rows)\n",
    "- Diastolic BP: 25 <= x <= 150 (excludes 315 rows)\n",
    "\n",
    "**Ethnicity Mapping**\n",
    "- 33 verschiedene werden auf 5 gemappt: Asian, Black, Unknown, White, Other\n",
    "\n",
    "**ICD Codes**\n",
    "- One ICD-9 code (707.24) cannot be translated and the corresponding row was excluded (1 row)\n",
    "\n",
    "**Chief Complaints**\n",
    "- 27687 unterschiedliche Kategorien wurden auf auf 310 geclustert (309 + \"Other\")\n",
    "- Länge des DataFrames: 141461, hiervon sind 646 NaN-Werte (0.46%). Dies waren i.W. \"Transfer\" oder unsinnige Angaben \"//\", \"-\", ... und wurden daher pd.NA gesetzt.\n",
    "- Anzahl der 'Other' Cluster: 38708 (27.36%)\n",
    "- Top 20 Einträge mit %-Anteil:\n",
    "   - abdominal pain                  8.413166\n",
    "   - chest pain                      4.741682\n",
    "   - dyspnea                         4.379505\n",
    "   - fever                           2.619749\n",
    "   - sp fall                         2.464226\n",
    "   - weakness                        1.933033\n",
    "   - abnormal labs                   1.764017\n",
    "   - nausea vomiting                 1.755495\n",
    "   - altered mental status           1.709335\n",
    "   - wound eval                      1.428825\n",
    "   - bright red blood per rectum     1.303838\n",
    "   - back pain                       1.234954\n",
    "   - suicidal ideation               1.222881\n",
    "   - headache                        0.954444\n",
    "   - shortness of breath             0.946632\n",
    "   - ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from pyicd.utils.icd_tools import icd9_to_icd10\n",
    "from functools import lru_cache\n",
    "from rapidfuzz import process, fuzz\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/20250301_data.csv\"\n",
    "icd_path = \"icd10_blocks.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions\n",
    "## Temperature Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_temperature(\n",
    "    df: pd.DataFrame,\n",
    "    temp_column: str,\n",
    "    f_threshold: float = 50.0,\n",
    "    c_min: float = 30.0,\n",
    "    c_max: float = 45.0,\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Standardize a temperature column to Celsius, marking implausible or malformed\n",
    "    entries as NaN.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input DataFrame.\n",
    "    temp_column : str\n",
    "        Name of the column containing temperature readings (mixed °F/°C).\n",
    "    f_threshold : float, default=50.0\n",
    "        Any reading >= this is treated as °F and converted; otherwise assumed °C.\n",
    "    c_min : float, default=30.0\n",
    "        Minimum plausible body temperature in °C.\n",
    "    c_max : float, default=45.0\n",
    "        Maximum plausible body temperature in °C.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        Temperatures in °C (Pandas Nullable Float64 dtype), out-of-range or invalid as NaN (pd.NA).\n",
    "    \"\"\"\n",
    "    if temp_column not in df.columns:\n",
    "        raise KeyError(f\"Column '{temp_column}' not found in DataFrame.\")\n",
    "\n",
    "    col = df[temp_column]\n",
    "    temps = pd.to_numeric(col, errors=\"coerce\")\n",
    "    is_f = temps >= f_threshold\n",
    "\n",
    "    c_temps = temps.copy()\n",
    "    c_temps[is_f] = (temps[is_f] - 32) * 5.0 / 9.0\n",
    "\n",
    "    mask_implausible = (c_temps < c_min) | (c_temps > c_max)\n",
    "    c_temps[mask_implausible] = pd.NA\n",
    "\n",
    "    c_temps = c_temps.round(1).astype('Float64')\n",
    "\n",
    "    return c_temps\n",
    "\n",
    "# Example usage:\n",
    "# df['temperature_clean'] = preprocess_temperature(df, 'temperature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vital Signs Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_vital_signs(\n",
    "    df: pd.DataFrame,\n",
    "    column: str,\n",
    "    min_valid: int,\n",
    "    max_valid: int,\n",
    "    winsorize: bool = False,\n",
    "    winsor_limits: tuple = (0.01, 0.99),\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Clean and optionally winsorize a vital sign column.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with vital signs.\n",
    "    column : str\n",
    "        Column name to clean.\n",
    "    min_valid : float\n",
    "        Minimum plausible value.\n",
    "    max_valid : float\n",
    "        Maximum plausible value.\n",
    "    winsorize : bool, default=False\n",
    "        Whether to apply winsorizing.\n",
    "    winsor_limits : tuple, default=(0.01, 0.99)\n",
    "        Winsorizing limits (lower, upper percentiles).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        Cleaned (and optionally winsorized) column as nullable integer (Int64).\n",
    "    \"\"\"\n",
    "    series = pd.to_numeric(df[column], errors='coerce')\n",
    "    series[(series < min_valid) | (series > max_valid)] = pd.NA\n",
    "\n",
    "    if winsorize:\n",
    "        lower = series.quantile(winsor_limits[0])\n",
    "        upper = series.quantile(winsor_limits[1])\n",
    "        series = series.clip(lower, upper)\n",
    "\n",
    "    series = series.round().astype('Int64')\n",
    "\n",
    "    return series\n",
    "\n",
    "# Example usage\n",
    "# df['heart_rate_clean'] = preprocess_vital_signs(df, 'heart_rate', min_valid=30, max_valid=220)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEWS Score Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_news_score(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Berechnet den NEWS-Score (ohne NEWS2-Erweiterungen, SpO₂-Scale 1,\n",
    "    und ohne Zusatzpunkt für O₂-Therapie) rein vektorbasiert.\n",
    "    https://pubmed.ncbi.nlm.nih.gov/23295778/\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Muss die Spalten  'resprate', 'o2sat', 'sbp', 'heartrate',\n",
    "        'acvpu'  und 'temperature' enthalten.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        Eine Serie namens 'news_score' mit derselben Indexlänge wie `df`.\n",
    "        Fehlende Werte in irgendeiner Eingangsspalten führen zu NA im Ergebnis.\n",
    "    \"\"\"\n",
    "    required = {\"resprate\", \"o2sat\", \"sbp\", \"heartrate\", \"acvpu\", \"temperature\"}\n",
    "    missing  = required.difference(df.columns)\n",
    "    if missing:\n",
    "        raise KeyError(f\"DataFrame fehlt folgende Spalten: {', '.join(missing)}\")\n",
    "\n",
    "    # --- RESPIRATORY RATE ----------------------------------------------------\n",
    "    rr_src = df.resprate.astype(float)\n",
    "    rr = np.select(\n",
    "        [rr_src <= 8,\n",
    "         rr_src.between(9, 11, inclusive=\"both\"),\n",
    "         rr_src.between(21, 24, inclusive=\"both\"),\n",
    "         rr_src >= 25],\n",
    "        [3, 1, 2, 3], default=0\n",
    "    )\n",
    "\n",
    "    # --- SpO₂ (Scale 1) ------------------------------------------------------\n",
    "    spo2_src = df.o2sat.astype(float)\n",
    "    spo2 = np.select(\n",
    "        [spo2_src <= 91,\n",
    "         spo2_src.between(92, 93, inclusive=\"both\"),\n",
    "         spo2_src.between(94, 95, inclusive=\"both\"),\n",
    "         spo2_src >= 96],\n",
    "        [3, 2, 1, 0], default=0\n",
    "    )\n",
    "\n",
    "    # --- SYSTOLIC BLOOD PRESSURE --------------------------------------------\n",
    "    sbp_src = df.sbp.astype(float)\n",
    "    sbp = np.select(\n",
    "        [sbp_src <= 90,\n",
    "         sbp_src.between(91, 100, inclusive=\"both\"),\n",
    "         sbp_src.between(101, 110, inclusive=\"both\"),\n",
    "         sbp_src >= 220],\n",
    "        [3, 2, 1, 3], default=0          # 111-219 → 0 Punkte\n",
    "    )\n",
    "\n",
    "    # --- HEART RATE ----------------------------------------------------------\n",
    "    hr_src = df.heartrate.astype(float)\n",
    "    hr = np.select(\n",
    "        [hr_src <= 40,\n",
    "         hr_src.between(41, 50, inclusive=\"both\"),\n",
    "         hr_src.between(51, 90, inclusive=\"both\"),\n",
    "         hr_src.between(91, 110, inclusive=\"both\"),\n",
    "         hr_src.between(111, 130, inclusive=\"both\"),\n",
    "         hr_src >= 131],\n",
    "        [3, 1, 0, 1, 2, 3]\n",
    "    )\n",
    "\n",
    "    # --- TEMPERATURE ---------------------------------------------------------\n",
    "    temp_src = df.temperature.astype(float)\n",
    "    temp = np.select(\n",
    "        [temp_src <= 35.0,\n",
    "         temp_src.between(35.1, 36.0, inclusive=\"both\"),\n",
    "         temp_src.between(36.1, 38.0, inclusive=\"both\"),\n",
    "         temp_src.between(38.1, 39.0, inclusive=\"both\"),\n",
    "         temp_src >= 39.1],\n",
    "        [3, 1, 0, 1, 2]\n",
    "    )\n",
    "\n",
    "    # --- ACVPU ---------------------------------------------------------------\n",
    "    acvpu = np.where(df.acvpu.isin([\"C\", \"V\", \"P\", \"U\"]), 3, 0)\n",
    "\n",
    "    # --- SUMME ---------------------------------------------------------------\n",
    "    total_numeric = rr + spo2 + sbp + hr + temp + acvpu\n",
    "\n",
    "    cat_type  = pd.CategoricalDtype(categories=range(19), ordered=True)\n",
    "    news_score = pd.Series(total_numeric, index=df.index,\n",
    "                           name=\"news_score\", dtype=cat_type)\n",
    "\n",
    "    # --- NA-Propagation ------------------------------------------------------\n",
    "    na_mask = df[list(required)].isna().any(axis=1)\n",
    "    news_score[na_mask] = pd.NA\n",
    "\n",
    "    return news_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICD-9 Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_icd9_series_to_icd10(df: pd.DataFrame, icd_colname: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Nimmt ein DataFrame mit den Spalten 'icd_version' und 'icd_code' und\n",
    "    gibt eine pd.Series zurück, die für alle ICD-9-Einträge (icd_version == 9)\n",
    "    den entsprechenden ICD-10-Code liefert (letztes Ergebnis von icd9_to_icd10),\n",
    "    und für alle anderen Zeilen den originalen (gestrippten) icd_code behält.\n",
    "    \n",
    "    Beispiel:\n",
    "        df['icd_new'] = convert_icd9_series_to_icd10(df)\n",
    "    \"\"\"\n",
    "    # 1) Ursprüngliche Codes als String und gestrippt\n",
    "    codes = df[icd_colname].astype(str).str.strip()\n",
    "    # 2) Maske für ICD-9-Einträge\n",
    "    mask = df['icd_version'] == 9\n",
    "\n",
    "    # 3) Einmalige Codes für die Maske\n",
    "    unique_codes = codes[mask].dropna().unique()\n",
    "\n",
    "    # 4) Mapping ICD-9 → ICD-10 (letztes Ergebnis oder pd.NA)\n",
    "    mapping: dict = {}\n",
    "    for code in unique_codes:\n",
    "        if not isinstance(code, str):\n",
    "            mapping[code] = pd.NA\n",
    "            continue\n",
    "        res = icd9_to_icd10(icd_code=code, flag=None, show_flags=False)\n",
    "        mapping[code] = res.iloc[-1]['icd10'] if not res.empty else pd.NA\n",
    "\n",
    "    # 5) Neue Series anlegen und befüllen\n",
    "    icd_new = pd.Series(pd.NA, index=df.index, dtype=\"object\")\n",
    "    # für ICD-9: zugeordnete ICD-10-Codes\n",
    "    icd_new.loc[mask] = codes[mask].map(mapping)\n",
    "    # für alle anderen: originales (gestripptes) Code-Feld\n",
    "    icd_new.loc[~mask] = codes[~mask]\n",
    "\n",
    "    return icd_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICD-10 Mapping to Subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=1)\n",
    "def _load_blocks(blocks_csv_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Lädt und bereitet das ICD-10-Blocks-CSV vor:\n",
    "    - Einlesen mit Trennzeichen ';'\n",
    "    - Whitespace-Trimming der wichtigen Spalten\n",
    "    - Erzeugen einer kombinierten 'Block'-Spalte\n",
    "    \"\"\"\n",
    "    df_blocks = pd.read_csv(blocks_csv_path, sep=';', dtype=str)\n",
    "    for col in [\"Start\", \"End\", \"Description\"]:\n",
    "        df_blocks[col] = df_blocks[col].str.strip()\n",
    "    df_blocks[\"Block\"] = df_blocks[\"Start\"] + \"-\" + df_blocks[\"End\"]\n",
    "    return df_blocks\n",
    "\n",
    "def get_icd_info(\n",
    "    icd_code: str,\n",
    "    blocks_csv_path: str = \"icd10_blocks.csv\"\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Gibt für einen einzelnen ICD-Code den zugehörigen Block und die Description zurück.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    icd_code : str\n",
    "        Der ICD-Code (z.B. 'M05.3' oder 'A01').\n",
    "    blocks_csv_path : str, optional\n",
    "        Pfad zur CSV-Datei mit den ICD-10-Blocks (Default: 'icd10_blocks.csv').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.Series\n",
    "        Series mit zwei Einträgen:\n",
    "        - 'icd_block': z.B. 'M05-M14' oder None\n",
    "        - 'icd_desc' : z.B. 'Inflammatory polyarthropathies' oder None\n",
    "    \"\"\"\n",
    "    # Null-/Nan-Fälle\n",
    "    if icd_code is None or (isinstance(icd_code, float) and pd.isna(icd_code)):\n",
    "        return pd.Series({\"icd_block\": None, \"icd_desc\": None})\n",
    "    if not isinstance(icd_code, str):\n",
    "        icd_code = str(icd_code)\n",
    "\n",
    "    # Normierung: Punkte entfernen, Großschreibung, nur 3 Zeichen\n",
    "    code3 = icd_code.replace(\".\", \"\").upper()[:3]\n",
    "\n",
    "    # Special case\n",
    "    if code3 == \"M1A\":\n",
    "        return pd.Series({\n",
    "            \"icd_block\": \"M05-M14\",\n",
    "            \"icd_desc\":  \"Inflammatory polyarthropathies\"\n",
    "        })\n",
    "\n",
    "    # Daten laden (erstes Mal)\n",
    "    blocks = _load_blocks(blocks_csv_path)\n",
    "\n",
    "    # Zeile finden, bei der Start <= code3 <= End\n",
    "    match = blocks[\n",
    "        (blocks[\"Start\"] <= code3) &\n",
    "        (blocks[\"End\"]   >= code3)\n",
    "    ]\n",
    "    if not match.empty:\n",
    "        row = match.iloc[0]\n",
    "        return pd.Series({\n",
    "            \"icd_block\": row[\"Block\"],\n",
    "            \"icd_desc\":  row[\"Description\"]\n",
    "        })\n",
    "\n",
    "    # Kein Treffer\n",
    "    return pd.Series({\"icd_block\": None, \"icd_desc\": None})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chief Complaint Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Normalize text: lowercase, remove punctuation, expand medical abbreviations.\"\"\"\n",
    "    text = str(text).lower().strip()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    abbreviations = {\n",
    "        r\"\\babd\\b\": \"abdominal\",\n",
    "        r\"\\babn\\b\": \"abnormal\",\n",
    "        r\"\\babnl\\b\": \"abnormal\",\n",
    "        r\"\\bevall\\b\": \"evaluation\",\n",
    "        r\"\\bfttl\\b\": \"failure to thrive\",\n",
    "        r\"\\bsvtl\\b\": \"supraventricular tachycardia\",\n",
    "        r\"\\btibfibl\\b\": \"tibia fibula\",\n",
    "        r\"\\baaal\\b\": \"abdominal aortic aneurysm\",\n",
    "        r\"\\bichl\\b\": \"intracerebral hemorrhage\",\n",
    "        r\"\\bsbol\\b\": \"small bowerl obstruction\",\n",
    "        r\"\\bsdhl\\b\": \"subdural hematoma\",\n",
    "        r\"\\bchf\\b\": \"congestive heart failure\",\n",
    "        r\"\\biph\\b\": \"intraparenchymal hemorrhage\",\n",
    "        r\"\\b b \\b\": \"bilateral\",\n",
    "        r\"\\bafib\\b\": \"atrial fibrillation\",\n",
    "        r\"\\blbp\\b\": \"lower back pain\",\n",
    "        r\"\\bcspine\\b\": \"cervical spine\",\n",
    "        r\"\\bsob\\b\": \"shortness of breath\",\n",
    "        r\"\\bn/v\\b\": \"nausea vomiting\",\n",
    "        r\"\\bnv\\b\": \"nausea vomiting\",\n",
    "        r\"\\bnvd\\b\": \"nausea vomiting diarrhea\",\n",
    "        r\"\\bha\\b\": \"headache\",\n",
    "        r\"\\bcp\\b\": \"chest pain\",\n",
    "        r\"\\buti\\b\": \"urinary tract infection\",\n",
    "        r\"\\bsi\\b\": \"suicidal ideation\",\n",
    "        r\"\\bbrbpr\\b\": \"bright red blood per rectum\",\n",
    "        r\"\\bfx\\b\": \"fracture\",\n",
    "        r\"\\bili\\b\": \"iliac\",\n",
    "        r\"\\blac\\b\": \"laceration\",\n",
    "        r\"\\bloc\\b\": \"loss of consciousness\",\n",
    "        r\"\\bgib\\b\": \"gastrointestinal bleeding\",\n",
    "        r\"\\btia\\b\": \"transient ischemic attack\",\n",
    "        r\"\\bdka\\b\": \"diabetic ketoacidosis\",\n",
    "        r\"\\bams\\b\": \"altered mental status\",\n",
    "        r\"\\betoh\\b\": \"alcohol intoxication\",\n",
    "        r\"\\bhtn\\b\": \"hypertension\",\n",
    "        r\"\\bdm\\b\": \"diabetes mellitus\",\n",
    "        r\"\\bhld\\b\": \"hyperlipidemia\",\n",
    "        r\"\\bcad\\b\": \"coronary artery disease\",\n",
    "        r\"\\bt/a\\b\": \"tonsillectomy and adenoidectomy\",\n",
    "        r\"\\bcva\\b\": \"cerebrovascular accident\",\n",
    "        r\"\\bmvc\\b\": \"motor vehicle collision\",\n",
    "        r\"\\bod\\b\": \"overdose\",\n",
    "        r\"\\bsz\\b\": \"seizure\",\n",
    "        r\"\\ba fib\\b\": \"atrial fibrillation\",\n",
    "        r\"\\bpe\\b\": \"pulmonary embolism\",\n",
    "        r\"\\bdvt\\b\": \"deep vein thrombosis\",\n",
    "        r\"\\brh\\b\": \"rheumatoid arthritis\",\n",
    "        r\"\\bgi\\b\": \"gastrointestinal\",\n",
    "        r\"\\bruq\\b\": \"right upper quadrant\",\n",
    "        r\"\\brlq\\b\": \"right lower quadrant\",\n",
    "        r\"\\bluq\\b\": \"left upper quadrant\",\n",
    "        r\"\\bllq\\b\": \"left lower quadrant\",\n",
    "        r\"\\bsah\\b\": \"subarachnoid hemorrhage\",\n",
    "        r\"\\bs\\/p\\b\": \"\",\n",
    "        r\"\\bh\\/o\\b\": \"\",\n",
    "        r\"\\bl\\b\": \"\",\n",
    "        r\"\\br\\b\": \"\",\n",
    "        r\"\\b-\\b\": \"\",\n",
    "        r\"\\btransfer\\b\": \"\",\n",
    "    }\n",
    "    for abbr, full in abbreviations.items():\n",
    "        text = re.sub(abbr, full, text)\n",
    "    # alles Mehrfach-Leerzeichen zu einem\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def cluster_complaints(df, col_name, num_clusters=499, threshold=80):\n",
    "    \"\"\"\n",
    "    Cluster complaints by normalizing them and grouping via fuzzy matching.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Eingabe-DataFrame.\n",
    "        col_name (str): Spaltenname mit den Original-Beschwerden.\n",
    "        num_clusters (int): Anzahl Basis-Cluster (häufigste Phrasen).\n",
    "        threshold (int): Fuzzy-Matching-Schwelle (0–100).\n",
    "    Returns:\n",
    "        pd.Series: Cluster-Labels für jede Zeile.\n",
    "    \"\"\"\n",
    "    # 1) Normalisierung\n",
    "    norms = df[col_name].astype(str).apply(preprocess_text)\n",
    "    \n",
    "    # 2) Häufigste Phrasen ermitteln\n",
    "    freq = norms.value_counts()\n",
    "    unique_phrases = freq.index.tolist()\n",
    "    base_clusters = unique_phrases[:num_clusters]\n",
    "    # print(f\"Base clusters: {base_clusters}\")\n",
    "\n",
    "    # 3) Fuzzy-Cluster-Zuordnung\n",
    "    clusters = {}\n",
    "    assigned = set()\n",
    "    for base in base_clusters:\n",
    "        if base in assigned:\n",
    "            continue\n",
    "        clusters[base] = base\n",
    "        assigned.add(base)\n",
    "        matches = process.extract(\n",
    "            base, unique_phrases,\n",
    "            scorer=fuzz.token_set_ratio,\n",
    "            score_cutoff=threshold\n",
    "        )\n",
    "        for match_phrase, score, _ in matches:\n",
    "            if match_phrase not in assigned:\n",
    "                clusters[match_phrase] = base\n",
    "                assigned.add(match_phrase)\n",
    "    \n",
    "    # 4) Rest zu „Other“\n",
    "    for phrase in unique_phrases:\n",
    "        if phrase not in clusters:\n",
    "            clusters[phrase] = \"Other\"\n",
    "    \n",
    "    # 5) Series zurückgeben\n",
    "    return norms.map(clusters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Routine\n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path, low_memory=False) # Use low_memory=False to prevent dtype issues with large files\n",
    "p = Path(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set correct dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['resprate', 'o2sat', 'sbp', 'dbp', 'heartrate']:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce').astype(int)\n",
    "\n",
    "for col in ['ed_intime', 'hadm_time']:\n",
    "    df[col] = pd.to_datetime(df[col])  # falls Unix-Timestamp\n",
    "    df[col] = pd.to_datetime(df[col], unit='s', origin='unix')\n",
    "    \n",
    "df['icu_within_24h'] = df['icu_within_24h'].map({'Yes': True, 'No': False})\n",
    "df['acvpu'] = pd.Categorical(df['acvpu'], categories=['A', 'C', 'V', 'P', 'U'], ordered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Additional Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['arrival_hour'] = df['ed_intime'].dt.hour\n",
    "df['arrival_dayofweek'] = df['ed_intime'].dt.dayofweek\n",
    "df['night_arrival'] = (df['arrival_hour'] >= 22) | (df['arrival_hour'] <= 6).astype(bool)\n",
    "df['weekend_arrival'] = df['arrival_dayofweek'].isin([5, 6]).astype(bool)\n",
    "# df['time_to_admission_hours'] = round((df['hadm_time'] - df['ed_intime']).dt.total_seconds() / 3600, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Vital Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['temperature'] = preprocess_temperature(df, 'temperature', f_threshold=50.0, c_min=30.0, c_max=45.0) # Thresh 50.0, c_min 30.0, c_max 45.0\n",
    "df['heartrate'] = preprocess_vital_signs(df, 'heartrate', min_valid=20, max_valid=240, winsorize=False) # min_valid 20, max_valid 240\n",
    "df['resprate'] = preprocess_vital_signs(df, 'resprate', min_valid=1, max_valid=70, winsorize=False) # min_valid 1, max_valid 70\n",
    "df['o2sat'] = preprocess_vital_signs(df, 'o2sat', min_valid=20, max_valid=100, winsorize=False) # min_valid 20, max_valid 100\n",
    "df['sbp'] = preprocess_vital_signs(df, 'sbp', min_valid=30, max_valid=300, winsorize=False) # min_valid 30, max_valid 300\n",
    "df['dbp'] = preprocess_vital_signs(df, 'dbp', min_valid=25, max_valid=150, winsorize=False) # min_valid 25, max_valid 150\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEWS Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['news_score'] = calculate_news_score(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethinicity Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der unterschiedlichen Ethnicity-Kategorien in 'race' vor dem Mapping: 33\n",
      "Anzahl der unterschiedlichen Ethnicity-Kategorien 'in race_grouped' nach dem Mapping: 5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Anzahl der unterschiedlichen Ethnicity-Kategorien in 'race' vor dem Mapping: {df['race'].nunique()}\")\n",
    "# 1) Extract the first occurrence of any of your keywords (case‑insensitive)\n",
    "extracted = df['race'].str.extract(r'(?i)(asian|white|black|unknown)', expand=False)\n",
    "\n",
    "# 2) Map back to the desired category names, fill all others as 'Other'\n",
    "df['race_grouped'] = (\n",
    "    extracted\n",
    "      .str.lower()\n",
    "      .map({\n",
    "          'asian':   'Asian',\n",
    "          'white':   'White',\n",
    "          'black':   'Black',\n",
    "          'unknown': 'Unknown',\n",
    "      })\n",
    "      .fillna('Other')\n",
    ")\n",
    "# print(df[['race', 'race_grouped']].head(50))\n",
    "print(f\"Anzahl der unterschiedlichen Ethnicity-Kategorien 'in race_grouped' nach dem Mapping: {df['race_grouped'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnoses Preprocessing\n",
    "### Map ICD-9 to ICD-10\n",
    "Some codes will not be found, e.g. icd9_to_icd10(icd_code=\"70724\", flag=None, show_flags=True) remains empty. This results from complete abscence of group 707.2 as it has no mapping correspondence in ICD-10 (https://www.icd10data.com/Convert/707.24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['icd10'] = convert_icd9_series_to_icd10(df, icd_colname='icd_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map ICD-10 Codes to Subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"icd_block\", \"icd_desc\"]] = df[\"icd10\"].apply(\n",
    "    lambda code: get_icd_info(code, blocks_csv_path=icd_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Chief Complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der unterschiedlichen Chief Complaint-Kategorien 'in chiefcomplaint' vor dem Clustern: 27687\n",
      "Anzahl der unterschiedlichen Chief Complaint-Kategorien 'in chiefcomplaint_clustered' nach dem Clustern: 310\n"
     ]
    }
   ],
   "source": [
    "print(f\"Anzahl der unterschiedlichen Chief Complaint-Kategorien 'in chiefcomplaint' vor dem Clustern: {df['chiefcomplaint'].nunique()}\")\n",
    "df['chiefcomplaint_clustered'] = cluster_complaints(\n",
    "    df,\n",
    "    col_name='chiefcomplaint',\n",
    "    num_clusters=499,\n",
    "    threshold=80\n",
    ")\n",
    "print(f\"Anzahl der unterschiedlichen Chief Complaint-Kategorien 'in chiefcomplaint_clustered' nach dem Clustern: {df['chiefcomplaint_clustered'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leere Werte in 'chiefcomplaint_clustered' durch pd.NA ersetzen\n",
    "df.loc[df['chiefcomplaint_clustered'] == '', 'chiefcomplaint_clustered'] = pd.NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Dataframe Arrangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=[\"race\", \"chiefcomplaint\", \"icd_version\", \"diagnosis_text\", \"subject_id\", \"ed_stay_id\", \"ed_intime\", \"hadm_id\", \n",
    "                      \"hadm_time\", \"arrival_hour\", \"arrival_dayofweek\", \"icd_code\", \"icd_desc\", \"icd10\"])\n",
    "\n",
    "# Rename columns to match the desired output\n",
    "df = df.rename(columns={\"race_grouped\": \"ethnicity\", \"chiefcomplaint_clustered\": \"chief_complaint\", \"sbp\": \"systolic_bp\", \"dbp\": \"diastolic_bp\",\n",
    "                        \"acvpu\": \"consciousness_level\", \"icu_within_24h\": \"icu_admission_24h\", \"o2sat\": \"oxygen_saturation\", \"resprate\": \"respiratory_rate\",\n",
    "                        \"heartrate\": \"heart_rate\"})\n",
    "\n",
    "# Reorder columns to match the desired output\n",
    "df = df[['icu_admission_24h', 'age', 'gender', 'ethnicity', 'consciousness_level', 'temperature', 'heart_rate', 'respiratory_rate',\n",
    "         'oxygen_saturation', 'systolic_bp', 'diastolic_bp', 'news_score', 'night_arrival', 'weekend_arrival', 'chief_complaint',\n",
    "         'icd_block']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse der NA-Werte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Zeilen mit mind. 1 NA-Wert in einer Spalte: 1120\n",
      "Anzahl der Zeilen mit fehlenden Werten:\n",
      "923 Zeilen haben genau 1 fehlende Werte\n",
      "158 Zeilen haben genau 2 fehlende Werte\n",
      "38 Zeilen haben genau 3 fehlende Werte\n",
      "1 Zeilen haben genau 4 fehlende Werte\n",
      "\n",
      "Zusammenfassung der NA-Werte pro Spalte:\n",
      "646 NA-Werte in Spalte 'chief_complaint'\n",
      "315 NA-Werte in Spalte 'diastolic_bp'\n",
      "196 NA-Werte in Spalte 'news_score'\n",
      "63 NA-Werte in Spalte 'systolic_bp'\n",
      "58 NA-Werte in Spalte 'temperature'\n",
      "51 NA-Werte in Spalte 'oxygen_saturation'\n",
      "15 NA-Werte in Spalte 'respiratory_rate'\n",
      "12 NA-Werte in Spalte 'heart_rate'\n",
      "1 NA-Werte in Spalte 'icd_block'\n"
     ]
    }
   ],
   "source": [
    "df_missing = df[df.isna().any(axis=1)].reset_index(drop=True)\n",
    "# df = df.dropna(how='any').reset_index(drop=True)\n",
    "\n",
    "print(f\"Anzahl der Zeilen mit mind. 1 NA-Wert in einer Spalte: {df_missing.shape[0]}\")\n",
    "\n",
    "# Anzahl fehlender Werte pro Zeile\n",
    "na_counts_per_row = df_missing.isna().sum(axis=1)\n",
    "\n",
    "# Zusammenfassung: Wie viele Zeilen haben genau 1, 2, 3, ... NAs?\n",
    "na_summary_rows = na_counts_per_row.value_counts().sort_index()\n",
    "\n",
    "print(\"Anzahl der Zeilen mit fehlenden Werten:\")\n",
    "for count, num_rows in na_summary_rows.items():\n",
    "    print(f\"{num_rows} Zeilen haben genau {count} fehlende Werte\")\n",
    "\n",
    "# Optional: nur Zeilen mit mindestens einem NA\n",
    "print(\"\\nZusammenfassung der NA-Werte pro Spalte:\")\n",
    "na_summary_cols = df_missing.isna().sum()\n",
    "na_summary_cols = na_summary_cols[na_summary_cols > 0].sort_values(ascending=False)\n",
    "\n",
    "for col, count in na_summary_cols.items():\n",
    "    print(f\"{count} NA-Werte in Spalte '{col}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export of Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been saved at: data\\20250301_data_20250510_122405_final.csv\n",
      "   icu_admission_24h  age gender ethnicity consciousness_level  temperature  \\\n",
      "0              False   57      M     White                   A         37.4   \n",
      "1              False   62      M     Asian                   A         36.6   \n",
      "2              False   87      M     Other                   C         36.7   \n",
      "3              False   69      M     White                   A         36.1   \n",
      "4              False   69      M     White                   A         36.4   \n",
      "\n",
      "   heart_rate  respiratory_rate  oxygen_saturation  systolic_bp  diastolic_bp  \\\n",
      "0          93                18                100          136            69   \n",
      "1         109                15                100          127            75   \n",
      "2          59                16                 96           95            56   \n",
      "3          74                16                 97          131            77   \n",
      "4          96                16                 98          148           101   \n",
      "\n",
      "  news_score  night_arrival  weekend_arrival chief_complaint icd_block  \n",
      "0          1          False            False   abnormal labs   C45-C49  \n",
      "1          1          False            False           Other   C45-C49  \n",
      "2          5          False            False           Other   C45-C49  \n",
      "3          0          False            False      wound eval   C45-C49  \n",
      "4          1          False             True           Other   C45-C49  \n"
     ]
    }
   ],
   "source": [
    "# Get the current date in YYYYMMDD format\n",
    "current_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Define custom text\n",
    "custom_text = \"_final\"\n",
    "\n",
    "file_name = f\"{current_timestamp}{custom_text}.csv\"\n",
    "file_path = p.with_name(p.stem + \"_\" + file_name)\n",
    "\n",
    "# Export DataFrame to CSV\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"CSV file has been saved at: {file_path}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icu_admission_24h</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>consciousness_level</th>\n",
       "      <th>temperature</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>respiratory_rate</th>\n",
       "      <th>oxygen_saturation</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>news_score</th>\n",
       "      <th>night_arrival</th>\n",
       "      <th>weekend_arrival</th>\n",
       "      <th>chief_complaint</th>\n",
       "      <th>icd_block</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>141461</td>\n",
       "      <td>141461.000000</td>\n",
       "      <td>141461</td>\n",
       "      <td>141461</td>\n",
       "      <td>141461</td>\n",
       "      <td>141403.0</td>\n",
       "      <td>141449.0</td>\n",
       "      <td>141446.0</td>\n",
       "      <td>141410.0</td>\n",
       "      <td>141398.0</td>\n",
       "      <td>141146.0</td>\n",
       "      <td>141265.0</td>\n",
       "      <td>141461</td>\n",
       "      <td>141461</td>\n",
       "      <td>140815</td>\n",
       "      <td>141460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>309</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>A</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Other</td>\n",
       "      <td>I30-I5A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>123931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72843</td>\n",
       "      <td>96364</td>\n",
       "      <td>130030</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>51109.0</td>\n",
       "      <td>114824</td>\n",
       "      <td>100957</td>\n",
       "      <td>38708</td>\n",
       "      <td>6756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>59.627622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.778854</td>\n",
       "      <td>86.594186</td>\n",
       "      <td>17.97404</td>\n",
       "      <td>97.82881</td>\n",
       "      <td>134.311857</td>\n",
       "      <td>75.110857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>18.381901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614528</td>\n",
       "      <td>18.999235</td>\n",
       "      <td>2.800053</td>\n",
       "      <td>2.416766</td>\n",
       "      <td>24.449336</td>\n",
       "      <td>15.701946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.4</td>\n",
       "      <td>73.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.7</td>\n",
       "      <td>85.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.1</td>\n",
       "      <td>227.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       icu_admission_24h            age  gender ethnicity consciousness_level  \\\n",
       "count             141461  141461.000000  141461    141461              141461   \n",
       "unique                 2            NaN       2         5                   5   \n",
       "top                False            NaN       F     White                   A   \n",
       "freq              123931            NaN   72843     96364              130030   \n",
       "mean                 NaN      59.627622     NaN       NaN                 NaN   \n",
       "std                  NaN      18.381901     NaN       NaN                 NaN   \n",
       "min                  NaN      18.000000     NaN       NaN                 NaN   \n",
       "25%                  NaN      47.000000     NaN       NaN                 NaN   \n",
       "50%                  NaN      61.000000     NaN       NaN                 NaN   \n",
       "75%                  NaN      74.000000     NaN       NaN                 NaN   \n",
       "max                  NaN      91.000000     NaN       NaN                 NaN   \n",
       "\n",
       "        temperature  heart_rate  respiratory_rate  oxygen_saturation  \\\n",
       "count      141403.0    141449.0          141446.0           141410.0   \n",
       "unique         <NA>        <NA>              <NA>               <NA>   \n",
       "top            <NA>        <NA>              <NA>               <NA>   \n",
       "freq           <NA>        <NA>              <NA>               <NA>   \n",
       "mean      36.778854   86.594186          17.97404           97.82881   \n",
       "std        0.614528   18.999235          2.800053           2.416766   \n",
       "min            30.0        20.0               1.0               42.0   \n",
       "25%            36.4        73.0              16.0               97.0   \n",
       "50%            36.7        85.0              18.0               98.0   \n",
       "75%            37.0        99.0              18.0              100.0   \n",
       "max            44.1       227.0              65.0              100.0   \n",
       "\n",
       "        systolic_bp  diastolic_bp  news_score night_arrival weekend_arrival  \\\n",
       "count      141398.0      141146.0    141265.0        141461          141461   \n",
       "unique         <NA>          <NA>        14.0             2               2   \n",
       "top            <NA>          <NA>         0.0         False           False   \n",
       "freq           <NA>          <NA>     51109.0        114824          100957   \n",
       "mean     134.311857     75.110857         NaN           NaN             NaN   \n",
       "std       24.449336     15.701946         NaN           NaN             NaN   \n",
       "min            50.0          25.0         NaN           NaN             NaN   \n",
       "25%           117.0          64.0         NaN           NaN             NaN   \n",
       "50%           132.0          75.0         NaN           NaN             NaN   \n",
       "75%           149.0          85.0         NaN           NaN             NaN   \n",
       "max           274.0         150.0         NaN           NaN             NaN   \n",
       "\n",
       "       chief_complaint icd_block  \n",
       "count           140815    141460  \n",
       "unique             309       225  \n",
       "top              Other   I30-I5A  \n",
       "freq             38708      6756  \n",
       "mean               NaN       NaN  \n",
       "std                NaN       NaN  \n",
       "min                NaN       NaN  \n",
       "25%                NaN       NaN  \n",
       "50%                NaN       NaN  \n",
       "75%                NaN       NaN  \n",
       "max                NaN       NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "General Purpose",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
